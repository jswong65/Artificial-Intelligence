# Artificial-Intelligence
Projects for Udacity Artificial Intelligence Nanodegree


## Term 1 - Foundation of Artificial Intelligence
### Projects
| Projects                                                       | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|----------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [AIND-Sudoku](https://github.com/jswong65/AIND-Sudoku)         | Build an intelligent agent that solve Sudoku using **Constraint Propagation** and **Search** process. Constraint Propagation (Elimination and Only Choice) helps to narrow down the space of possible answers. Sometime the puzzle might not be solved after leveraging Constraint Propagation. We can then apply a search algorithm (e.g., DFS) to traverse the candidates of possible solutions to identify a feasible one. The search can be started with the box with a minimal possible values.                                                                                                                                                                                                                                                                 |
| [AIND-Isolation](https://github.com/jswong65/AIND-Isolation)   | In this project, several techniques were applie to create a game agent for the Isolation game. To start leveraging mentioned strategies, a game tree (each node is a game state) is needed to be built to present all of the possible moves and the final result (win or lose). Such (win or loss) information can be propagated from bottom to the root to help play make a better move (**Minmax algorithm**). Minmax algorithm involves a pair of mutually recursive helper functions (MAX-VALUE and MIN-VALUE). Due to the large search space, **Iterative Deepening** is leveraged to obtain the best move with limited-depth exploration, and a evaluation function is required to calculated the score to be propagated (since no win or loss info now). Additionally, **Alpha-Beta Pruning** can be applied to reduce the search space.  |
| [AIND-Planning](https://github.com/jswong65/AIND-Planning)     | In this project, deterministic logistics planning problems for an Air Cargo transport system were solved using a planning search agent. Different search algorithms, including both non-heuristic and heuristic planning approaches, were implemented to find the optimal plan. Non-heuristic methods included **uniform cost search**, **bread first search**, and **depth-first graph search**. Heuristic approaches involved ignore preconditions and level sum heuristic using **A\* search**. |
| [AIND-Recognizer](https://github.com/jswong65/AIND-Recognizer) | In this project, we have to train a Hidden Markov Model to recognize gestures in American Sign Language. Additional features including, normalized Cartesian coordinates, polar coordinates, delta difference were implemented to enhance the recognition process. Moreover, **Log-likelihood using cross-validation folds** (CV), **Bayesian Information Criterion** (BIC), **Discriminative Information Criterion** (DIC) were applied to evaluate the number of hidden states.|

### Labs
* [AIND-simulated annealing](https://github.com/jswong65/AIND-Simulated_Annealing)
* [AIND-Pac_Man](https://github.com/jswong65/AIND-Pac_Man)

## Term 2 - Deep Learning
| Project | Description |
|-----------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [AIND-CNN](https://github.com/jswong65/AIND-CNN) | Use [Haar feature-based cascade classifiers](http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html) provided by OpenCV to detect human faces which would return a list of tuples (coordinates of a bounding box). In addition, I built a convolutional neural network (CNN) based on the Alexnet architecture with Keras for dog breed classification (8,351 images in 133 classes). Since this is a relatively small dataset, the accuracy of this model is quite low. Therefore, image augmentation was leveraged to generate more training samples. Additionally, the pre-trained CNN was applied to  capture the representation of input image to achieve the better performance (around 80% accuracy).  |
| [AIND-RNN](https://github.com/jswong65/AIND-RNN) | In this project, RNN using Long Short Term Memory (LSTM) is used to perform two tasks that are **time series predictions** (stock price) and **character-by-character text generation**. For the first task,  a two-layer RNN was built and trained as a **regression model** to predict the stock price, which achieves a 1.4% testing error.  For the second task, a 3- layer RNN model was built and trained as a **multi-class (Softmax) classifier** to guess the next character.   |
| [AIND-Machine Translation](https://github.com/jswong65/Keras_Machine_Translation) | Build and train 4 different models using Keras for English to French **Machine Translation**. **Model 1** is a simple RNN. **Model 2** is a RNN with Embedding. **Model 3** use a Bidirectional RNN. **Model 4** is a Encoder-decoder with Bidirectional RNN. To mitigate the issue of gradient vanishing, gated recurrent units (GRUs) are applied to build the RNN for all of the models. The **data preprocessing** both both input sequences (text in English) and target sequences (text in French) involves sentence **Tokenization**, **One Hot Encoding** for each word, and **sequence padding** (pad sentence that has a shorter length) |
